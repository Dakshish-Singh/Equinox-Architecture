{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyME9hfDLKkGwVjUHBHdwmk6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"940606fd00ca4dcab91d495b45c5ebde":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_91fb01be5753494b9259a48c3b9d6904","IPY_MODEL_7b89ba1156eb439883a3666b7680fe52","IPY_MODEL_7740199dfce043f59fef3bd7befd7399"],"layout":"IPY_MODEL_1d2bd00d79a74d8c94db974cadd974f1"}},"91fb01be5753494b9259a48c3b9d6904":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a55ebfddee7e4a2bbaaab6118b398ce0","placeholder":"​","style":"IPY_MODEL_209267951a7c4e5d96f6de7a96f60049","value":"Map: 100%"}},"7b89ba1156eb439883a3666b7680fe52":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_50e24e151ec047baa591130cb2020835","max":4358,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b91a36b649924deda90980a38356f9b1","value":4358}},"7740199dfce043f59fef3bd7befd7399":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9639e5b067f746fbbf95625e33968d83","placeholder":"​","style":"IPY_MODEL_b81201b4f8364f7bb8ceb0a8864931ed","value":" 4358/4358 [00:05&lt;00:00, 1519.66 examples/s]"}},"1d2bd00d79a74d8c94db974cadd974f1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a55ebfddee7e4a2bbaaab6118b398ce0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"209267951a7c4e5d96f6de7a96f60049":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"50e24e151ec047baa591130cb2020835":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b91a36b649924deda90980a38356f9b1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9639e5b067f746fbbf95625e33968d83":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b81201b4f8364f7bb8ceb0a8864931ed":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["!pip install datasets\n","!pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KaWG7nUcB619","executionInfo":{"status":"ok","timestamp":1725359798818,"user_tz":-330,"elapsed":30958,"user":{"displayName":"Dakshish Singh","userId":"11872715448538437314"}},"outputId":"da79bbe0-92dc-424e-8cc2-4609502ac9dc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting datasets\n","  Downloading datasets-2.21.0-py3-none-any.whl.metadata (21 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.15.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n","Collecting pyarrow>=15.0.0 (from datasets)\n","  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting multiprocess (from datasets)\n","  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n","Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.5)\n","Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.8)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.7.4)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","Downloading datasets-2.21.0-py3-none-any.whl (527 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m527.3/527.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: xxhash, pyarrow, dill, multiprocess, datasets\n","  Attempting uninstall: pyarrow\n","    Found existing installation: pyarrow 14.0.2\n","    Uninstalling pyarrow-14.0.2:\n","      Successfully uninstalled pyarrow-14.0.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n","ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed datasets-2.21.0 dill-0.3.8 multiprocess-0.70.16 pyarrow-17.0.0 xxhash-3.5.0\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.5)\n","Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.4)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.8)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.7.4)\n"]}]},{"cell_type":"code","source":["import torch\n","from transformers import AutoModelForCausalLM, AutoTokenizer\n","from datasets import load_dataset\n","\n","def evaluate_model_with_per_example_progress(dataset, model, tokenizer, context_length=128, print_every=100):\n","    model.eval()\n","\n","    total_loss = 0.0\n","    total_predictions = 0\n","    correct_predictions = 0\n","\n","    # Tokenize and process dataset\n","    def tokenize_function(example):\n","        return tokenizer(example['text'], truncation=True, padding='max_length', max_length=context_length)\n","\n","    tokenized_dataset = dataset.map(tokenize_function, batched=False)\n","\n","    # Convert the dataset to PyTorch tensors\n","    tokenized_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask'])\n","\n","    # Track total number of examples\n","    total_examples = len(tokenized_dataset)\n","\n","    with torch.no_grad():\n","        for i, example in enumerate(tokenized_dataset):\n","            input_ids = example['input_ids'].unsqueeze(0)  # Add batch dimension\n","            attention_mask = example['attention_mask'].unsqueeze(0)\n","\n","            # Move tensors to the same device as the model\n","            input_ids = input_ids.to(model.device)\n","            attention_mask = attention_mask.to(model.device)\n","\n","            # Get model output\n","            outputs = model(input_ids, attention_mask=attention_mask)\n","            predictions = outputs.logits\n","\n","            # Shift input_ids and labels by one to predict next token\n","            shift_logits = predictions[..., :-1, :].contiguous()\n","            shift_labels = input_ids[..., 1:].contiguous()\n","\n","            # Compute the loss\n","            loss_fct = torch.nn.CrossEntropyLoss(reduction='sum')\n","            loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n","\n","            total_loss += loss.item()\n","            total_predictions += shift_labels.numel()\n","\n","            # Calculate accuracy: compare the predicted token with the actual next token\n","            predicted_tokens = torch.argmax(shift_logits, dim=-1)\n","            correct_predictions += (predicted_tokens == shift_labels).sum().item()\n","\n","            # Print progress every N examples\n","            if (i + 1) % print_every == 0:\n","                current_perplexity = torch.exp(torch.tensor(total_loss / total_predictions)).item()\n","                current_accuracy = correct_predictions / total_predictions\n","                print(f\"Processed {i + 1}/{total_examples} examples. Current Perplexity: {current_perplexity:.2f}, Accuracy: {current_accuracy * 100:.2f}%\")\n","\n","    # Final metrics calculation\n","    perplexity = torch.exp(torch.tensor(total_loss / total_predictions)).item()\n","    accuracy = correct_predictions / total_predictions\n","\n","    return accuracy, perplexity\n","\n","# Load the model and tokenizer\n","model_name = \"microsoft/MiniLM-L12-H384-uncased\"\n","model = AutoModelForCausalLM.from_pretrained(model_name)\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","\n","# Load the PTB dataset\n","dataset = load_dataset(\"wikitext\", \"wikitext-103-raw-v1\", split='test')\n","\n","# Evaluate the model\n","context_length = 32  # Set the desired fixed context length\n","accuracy, perplexity = evaluate_model_with_per_example_progress(dataset, model, tokenizer, context_length, print_every=100)\n","print(f\"MiniLM Perplexity on PTB dataset with context length {context_length}: {perplexity:.2f}\")\n","print(f\"MiniLM Accuracy on PTB dataset with context length {context_length}: {accuracy * 100:.2f}%\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":902,"referenced_widgets":["940606fd00ca4dcab91d495b45c5ebde","91fb01be5753494b9259a48c3b9d6904","7b89ba1156eb439883a3666b7680fe52","7740199dfce043f59fef3bd7befd7399","1d2bd00d79a74d8c94db974cadd974f1","a55ebfddee7e4a2bbaaab6118b398ce0","209267951a7c4e5d96f6de7a96f60049","50e24e151ec047baa591130cb2020835","b91a36b649924deda90980a38356f9b1","9639e5b067f746fbbf95625e33968d83","b81201b4f8364f7bb8ceb0a8864931ed"]},"id":"8gVR69D3FeVP","executionInfo":{"status":"ok","timestamp":1725360523808,"user_tz":-330,"elapsed":363269,"user":{"displayName":"Dakshish Singh","userId":"11872715448538437314"}},"outputId":"f3cc400a-e830-4483-c585-42a8d7e897b8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["If you want to use `BertLMHeadModel` as a standalone, add `is_decoder=True.`\n","Some weights of BertLMHeadModel were not initialized from the model checkpoint at microsoft/MiniLM-L12-H384-uncased and are newly initialized: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/4358 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"940606fd00ca4dcab91d495b45c5ebde"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Processed 100/4358 examples. Current Perplexity: 41358.08, Accuracy: 0.03%\n","Processed 200/4358 examples. Current Perplexity: 40871.80, Accuracy: 0.02%\n","Processed 300/4358 examples. Current Perplexity: 40906.27, Accuracy: 0.01%\n","Processed 400/4358 examples. Current Perplexity: 41447.79, Accuracy: 0.01%\n","Processed 500/4358 examples. Current Perplexity: 41369.64, Accuracy: 0.01%\n","Processed 600/4358 examples. Current Perplexity: 41215.15, Accuracy: 0.01%\n","Processed 700/4358 examples. Current Perplexity: 41491.37, Accuracy: 0.00%\n","Processed 800/4358 examples. Current Perplexity: 41539.16, Accuracy: 0.00%\n","Processed 900/4358 examples. Current Perplexity: 41165.61, Accuracy: 0.00%\n","Processed 1000/4358 examples. Current Perplexity: 41250.86, Accuracy: 0.00%\n","Processed 1100/4358 examples. Current Perplexity: 41112.80, Accuracy: 0.00%\n","Processed 1200/4358 examples. Current Perplexity: 41022.26, Accuracy: 0.00%\n","Processed 1300/4358 examples. Current Perplexity: 41051.53, Accuracy: 0.00%\n","Processed 1400/4358 examples. Current Perplexity: 40913.60, Accuracy: 0.00%\n","Processed 1500/4358 examples. Current Perplexity: 40850.44, Accuracy: 0.00%\n","Processed 1600/4358 examples. Current Perplexity: 41062.89, Accuracy: 0.00%\n","Processed 1700/4358 examples. Current Perplexity: 41198.25, Accuracy: 0.00%\n","Processed 1800/4358 examples. Current Perplexity: 41335.05, Accuracy: 0.00%\n","Processed 1900/4358 examples. Current Perplexity: 41482.74, Accuracy: 0.00%\n","Processed 2000/4358 examples. Current Perplexity: 41427.08, Accuracy: 0.00%\n","Processed 2100/4358 examples. Current Perplexity: 40944.36, Accuracy: 0.00%\n","Processed 2200/4358 examples. Current Perplexity: 40957.05, Accuracy: 0.00%\n","Processed 2300/4358 examples. Current Perplexity: 40945.65, Accuracy: 0.00%\n","Processed 2400/4358 examples. Current Perplexity: 41007.55, Accuracy: 0.00%\n","Processed 2500/4358 examples. Current Perplexity: 41007.82, Accuracy: 0.00%\n","Processed 2600/4358 examples. Current Perplexity: 41036.58, Accuracy: 0.00%\n","Processed 2700/4358 examples. Current Perplexity: 41125.86, Accuracy: 0.00%\n","Processed 2800/4358 examples. Current Perplexity: 41170.68, Accuracy: 0.00%\n","Processed 2900/4358 examples. Current Perplexity: 41236.18, Accuracy: 0.00%\n","Processed 3000/4358 examples. Current Perplexity: 41259.98, Accuracy: 0.00%\n","Processed 3100/4358 examples. Current Perplexity: 41286.08, Accuracy: 0.00%\n","Processed 3200/4358 examples. Current Perplexity: 41255.02, Accuracy: 0.00%\n","Processed 3300/4358 examples. Current Perplexity: 41194.95, Accuracy: 0.00%\n","Processed 3400/4358 examples. Current Perplexity: 41120.80, Accuracy: 0.00%\n","Processed 3500/4358 examples. Current Perplexity: 41094.03, Accuracy: 0.00%\n","Processed 3600/4358 examples. Current Perplexity: 41085.45, Accuracy: 0.00%\n","Processed 3700/4358 examples. Current Perplexity: 41111.24, Accuracy: 0.00%\n","Processed 3800/4358 examples. Current Perplexity: 41117.63, Accuracy: 0.00%\n","Processed 3900/4358 examples. Current Perplexity: 41066.68, Accuracy: 0.00%\n","Processed 4000/4358 examples. Current Perplexity: 41040.61, Accuracy: 0.00%\n","Processed 4100/4358 examples. Current Perplexity: 41053.45, Accuracy: 0.00%\n","Processed 4200/4358 examples. Current Perplexity: 41128.61, Accuracy: 0.00%\n","Processed 4300/4358 examples. Current Perplexity: 41158.67, Accuracy: 0.00%\n","MiniLM Perplexity on PTB dataset with context length 32: 41163.41\n","MiniLM Accuracy on PTB dataset with context length 32: 0.00%\n"]}]},{"cell_type":"code","source":["#wiki-text 103 raw test set\n","#2-> 58385.12\n","#4-> 43948.05\n","#8-> 57331.96\n","#16->73945.55\n","#32->33567.81\n","#64->68098.13"],"metadata":{"id":"87ynyBPMpi4Q"},"execution_count":null,"outputs":[]}]}